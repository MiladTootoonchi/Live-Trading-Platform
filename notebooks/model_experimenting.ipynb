{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce012550",
   "metadata": {},
   "source": [
    "# Model Experimenting\n",
    "This notebook will work as an experiment on how well different ML models do on historical data for different stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f308b",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813ca6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "from live_trader.ml_model import ML_Pipeline, brier, basic_lstm, attention_bilstm\n",
    "from live_trader.ml_model.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "791a8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, Bidirectional,\n",
    "    Attention, LayerNormalization, Add, GlobalAveragePooling1D, \n",
    "    Conv1D, MultiHeadAttention, Reshape, Lambda, GRU\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from keras.saving import register_keras_serializable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e2a44",
   "metadata": {},
   "source": [
    "## Testing our models that are already made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d48ec8",
   "metadata": {},
   "source": [
    "### Basic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0f066c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
      "GOOG: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "side, _ = await basic_lstm(\"GOOG\")\n",
    "print(f\"GOOG: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92953d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "AAPL: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "side, _ = await basic_lstm(\"AAPL\")\n",
    "print(f\"AAPL: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e189c9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "MCFT: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "side, _ = await basic_lstm(\"MCFT\")\n",
    "print(f\"MCFT: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb762ce",
   "metadata": {},
   "source": [
    "### attention bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76bc9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "GOOG: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "side, _ = await attention_bilstm(\"GOOG\")\n",
    "print(f\"GOOG: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07527cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7149bc1e4220> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "AAPL: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "side, _ = await attention_bilstm(\"AAPL\")\n",
    "print(f\"AAPL: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0630e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7149bc221e40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n",
      "MCFT: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "side, _ = await attention_bilstm(\"MCFT\")\n",
    "print(f\"MCFT: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f0a9b",
   "metadata": {},
   "source": [
    "Both attention_bilstm and basic_lstm are not good models. Therefore, we will try out other models as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414af5d",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef95a1",
   "metadata": {},
   "source": [
    "### Temporal Convolutional Network (TCN-lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6abb39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tcn_lite(X_train_seq: Union[np.ndarray, list]) -> Model:\n",
    "    \"\"\"\n",
    "    Builds a lightweight Temporal Convolutional Network (TCN-style)\n",
    "    for noisy financial time series classification.\n",
    "\n",
    "    Designed to be robust to non-stationarity and overfitting.\n",
    "\n",
    "    Args:\n",
    "        X_train_seq (array-like):\n",
    "            Training sequences of shape (n_samples, time_steps, n_features)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras Model\n",
    "    \"\"\"\n",
    "    n_features = X_train_seq.shape[2]\n",
    "\n",
    "    inputs = Input(shape=(None, n_features))\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"causal\",\n",
    "        activation=\"relu\"\n",
    "    )(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=16,\n",
    "        kernel_size=3,\n",
    "        padding=\"causal\",\n",
    "        activation=\"relu\"\n",
    "    )(x)\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"tcn_lite\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            AUC(name=\"auc\"),\n",
    "            brier\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85265e6a",
   "metadata": {},
   "source": [
    "### PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffca0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_patchtst_lite(X_train_seq: Union[np.ndarray, list]) -> Model:\n",
    "    \"\"\"\n",
    "    Builds a lightweight PatchTST-style Transformer model for\n",
    "    noisy financial time series classification.\n",
    "\n",
    "    The model splits the time dimension into patches, embeds them,\n",
    "    and applies a Transformer encoder for temporal modeling.\n",
    "\n",
    "    Designed for robustness to non-stationarity and overfitting.\n",
    "\n",
    "    Args:\n",
    "        X_train_seq (array-like):\n",
    "            Training sequences of shape (n_samples, time_steps, n_features)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras Model\n",
    "    \"\"\"\n",
    "\n",
    "    patch_len: int = 16\n",
    "    d_model: int = 64\n",
    "    num_heads: int = 4\n",
    "    ff_dim: int = 128\n",
    "    dropout: float = 0.3\n",
    "\n",
    "    n_features = X_train_seq.shape[2]\n",
    "\n",
    "    inputs = Input(shape=(None, n_features))\n",
    "\n",
    "    # Patch embedding\n",
    "    x = Patchify(patch_len=patch_len, name=\"patchify\")(inputs)\n",
    "\n",
    "    x = Dense(d_model, activation=\"linear\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    # Transformer Encoder Block\n",
    "    attn_out = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model // num_heads,\n",
    "        dropout=dropout\n",
    "    )(x, x)\n",
    "\n",
    "    x = LayerNormalization()(x + attn_out)\n",
    "\n",
    "    ff_out = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    ff_out = Dropout(dropout)(ff_out)\n",
    "    ff_out = Dense(d_model)(ff_out)\n",
    "\n",
    "    x = LayerNormalization()(x + ff_out)\n",
    "\n",
    "    # Pooling & Head\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"patchtst_lite\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            AUC(name=\"auc\"),\n",
    "            brier\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ba0a3",
   "metadata": {},
   "source": [
    "### GNN (Graph-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf3ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gnn_lite(X_train_seq: Union[np.ndarray, list],) -> Model:\n",
    "    \"\"\"\n",
    "    Builds a lightweight Graph Neural Network (GNN-style) model\n",
    "    for noisy financial time series classification.\n",
    "\n",
    "    Nodes represent features (indicators).\n",
    "    Edges are learned implicitly via feature interactions.\n",
    "\n",
    "    Designed for robustness to:\n",
    "    - Non-stationarity\n",
    "    - Variable-length sequences\n",
    "    - Small batch sizes\n",
    "\n",
    "    Args:\n",
    "        X_train_seq (array-like):\n",
    "            Training sequences of shape (n_samples, time_steps, n_features)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras Model\n",
    "    \"\"\"\n",
    "\n",
    "    hidden_dim: int = 32\n",
    "    gnn_layers: int = 2\n",
    "    dropout: float = 0.3\n",
    "\n",
    "    n_features = X_train_seq.shape[2]\n",
    "\n",
    "    inputs = Input(shape=(None, n_features))\n",
    "\n",
    "    # Temporal aggregation\n",
    "    # (B, T, F) → (B, F)\n",
    "    x = GlobalAveragePooling1D(name=\"temporal_pool\")(inputs)\n",
    "\n",
    "    # Treat features as nodes\n",
    "    # (B, F) → (B, F, 1)\n",
    "    x = ExpandDims(axis=-1, name=\"expand_dims\")(x)\n",
    "\n",
    "    # GNN layers\n",
    "    for i in range(gnn_layers):\n",
    "        x = GraphMessagePassing(\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            name=f\"gnn_layer_{i}\"\n",
    "        )(x)\n",
    "\n",
    "    # Graph pooling\n",
    "    x = GlobalAveragePooling1D(name=\"graph_pool\")(x)\n",
    "\n",
    "    # Head\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"gnn_lite\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[AUC(name=\"auc\"), brier]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb8d0e",
   "metadata": {},
   "source": [
    "### Neural Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04f46ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder_classifier_lite(X_train_seq: Union[np.ndarray, list]) -> Model:\n",
    "    \"\"\"\n",
    "    Builds an Autoencoder + Classifier model for\n",
    "    neural anomaly detection in time series.\n",
    "\n",
    "    Fully compatible with Keras 3 and existing pipelines.\n",
    "\n",
    "    Args:\n",
    "        X_train_seq (array-like):\n",
    "            Training sequences of shape (n_samples, time_steps, n_features)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras Model\n",
    "    \"\"\"\n",
    "\n",
    "    latent_dim: int = 16\n",
    "    hidden_dim: int = 64\n",
    "    dropout: float = 0.3\n",
    "    recon_weight: float = 0.3\n",
    "\n",
    "    n_features = X_train_seq.shape[2]\n",
    "\n",
    "    model = AutoencoderClassifierLite(\n",
    "        n_features=n_features,\n",
    "        latent_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        dropout=dropout,\n",
    "        recon_weight=recon_weight,\n",
    "        name=\"autoencoder_classifier_lite\"\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[AUC(name=\"auc\"), brier]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05dbbc",
   "metadata": {},
   "source": [
    "### CNN-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1077d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_gru_lite(X_train_seq: Union[np.ndarray, list]) -> Model:\n",
    "    \"\"\"\n",
    "    Builds a lightweight CNN-GRU model for\n",
    "    noisy financial time series classification.\n",
    "\n",
    "    Combines shallow temporal convolutions for\n",
    "    local pattern extraction with a compact GRU\n",
    "    layer for sequence modeling.\n",
    "\n",
    "    Designed to be robust to non-stationarity\n",
    "    and overfitting.\n",
    "\n",
    "    Args:\n",
    "        X_train_seq (array-like):\n",
    "            Training sequences of shape\n",
    "            (n_samples, time_steps, n_features)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras Model\n",
    "    \"\"\"\n",
    "    n_features = X_train_seq.shape[2]\n",
    "\n",
    "    inputs = Input(shape=(None, n_features))\n",
    "\n",
    "    # ---- CNN block ----\n",
    "    x = Conv1D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=16,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\"\n",
    "    )(x)\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    # ---- GRU block ----\n",
    "    x = GRU(\n",
    "        units=32,\n",
    "        dropout=0.3\n",
    "    )(x)\n",
    "\n",
    "    # ---- Head ----\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"cnn_gru_lite\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            AUC(name=\"auc\"),\n",
    "            brier\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64087c52",
   "metadata": {},
   "source": [
    "## Training / Testing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ee13a",
   "metadata": {},
   "source": [
    "### TCN-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45b32b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "GOOG: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"GOOG\"\n",
    "side, _ = await ML_Pipeline(build_tcn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "142a1356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
      "AAPL: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "symbol = \"AAPL\"\n",
    "side, _ = await ML_Pipeline(build_tcn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c48343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
      "MCFT: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "symbol = \"MCFT\"\n",
    "side, _ = await ML_Pipeline(build_tcn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a82f6",
   "metadata": {},
   "source": [
    "### PathTST-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a4c4db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step\n",
      "GOOG: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"GOOG\"\n",
    "side, _ = await ML_Pipeline(build_patchtst_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d4e4723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
      "AAPL: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"AAPL\"\n",
    "side, _ = await ML_Pipeline(build_patchtst_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1be82256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
      "MCFT: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"MCFT\"\n",
    "side, _ = await ML_Pipeline(build_patchtst_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b33fc6",
   "metadata": {},
   "source": [
    "### GNN-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ec4a580",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'keras.src.models.functional.Functional'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'binary_crossentropy', 'loss_weights': None, 'metrics': [{'module': 'keras.metrics', 'class_name': 'AUC', 'config': {'name': 'auc', 'dtype': 'float32', 'num_thresholds': 200, 'curve': 'ROC', 'summation_method': 'interpolation', 'multi_label': False, 'num_labels': None, 'label_weights': None, 'from_logits': False}, 'registered_name': None}, {'module': 'builtins', 'class_name': 'function', 'config': 'Custom>brier', 'registered_name': 'function'}], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': False}}.\n\nException encountered: Could not locate class 'GraphMessagePassing'. Make sure custom classes and functions are decorated with `@keras.saving.register_keras_serializable()`. If they are already decorated, make sure they are all imported so that the decorator is run before trying to load them. Full object config: {'module': None, 'class_name': 'GraphMessagePassing', 'config': {'name': 'gnn_layer_0', 'hidden_dim': 32, 'dropout': 0.3, 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 128808718389504}}, 'registered_name': 'GraphMessagePassing', 'build_config': {'input_shape': [None, 14, 1]}, 'name': 'gnn_layer_0', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 14, 1], 'dtype': 'float32', 'keras_history': ['expand_dims', 0, 0]}}], 'kwargs': {}}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:733\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m     instance = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/models/model.py:823\u001b[39m, in \u001b[36mModel.from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[32m    829\u001b[39m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    832\u001b[39m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[32m    833\u001b[39m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/models/functional.py:561\u001b[39m, in \u001b[36mfunctional_from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m functional_config[\u001b[33m\"\u001b[39m\u001b[33mlayers\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m     \u001b[43mprocess_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/models/functional.py:528\u001b[39m, in \u001b[36mfunctional_from_config.<locals>.process_layer\u001b[39m\u001b[34m(layer_data)\u001b[39m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     layer = \u001b[43mserialization_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Operation):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:709\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m \u001b[38;5;28mcls\u001b[39m = \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, types.FunctionType):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:834\u001b[39m, in \u001b[36m_retrieve_class_or_fn\u001b[39m\u001b[34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[39m\n\u001b[32m    828\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    829\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not deserialize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m because \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    830\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mits parent module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cannot be imported. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    831\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    835\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Make sure custom classes and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    836\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfunctions are decorated with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    837\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m`@keras.saving.register_keras_serializable()`. If they are already \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    838\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdecorated, make sure they are all imported so that the decorator is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    839\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrun before trying to load them. Full object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    840\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: Could not locate class 'GraphMessagePassing'. Make sure custom classes and functions are decorated with `@keras.saving.register_keras_serializable()`. If they are already decorated, make sure they are all imported so that the decorator is run before trying to load them. Full object config: {'module': None, 'class_name': 'GraphMessagePassing', 'config': {'name': 'gnn_layer_0', 'hidden_dim': 32, 'dropout': 0.3, 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 128808718389504}}, 'registered_name': 'GraphMessagePassing', 'build_config': {'input_shape': [None, 14, 1]}, 'name': 'gnn_layer_0', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 14, 1], 'dtype': 'float32', 'keras_history': ['expand_dims', 0, 0]}}], 'kwargs': {}}]}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m symbol = \u001b[33m\"\u001b[39m\u001b[33mGOOG\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m side, _ = \u001b[38;5;28;01mawait\u001b[39;00m ML_Pipeline(build_gnn_lite, symbol, {})\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mside\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/src/live_trader/ml_model/training.py:198\u001b[39m, in \u001b[36mML_Pipeline\u001b[39m\u001b[34m(model_builder, symbol, position_data)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m MODEL_PATH.exists() \u001b[38;5;129;01mand\u001b[39;00m SCALER_PATH.exists():\n\u001b[32m    197\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading existing model for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     model = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m     scaler = joblib.load(SCALER_PATH)\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m CALIBRATOR_PATH.exists():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py:189\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    186\u001b[39m         is_keras_zip = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath,\n\u001b[32m    198\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    199\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    200\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    201\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:365\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    361\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m     )\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:442\u001b[39m, in \u001b[36m_load_model_from_fileobj\u001b[39m\u001b[34m(fileobj, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m zf.open(_CONFIG_FILENAME, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    440\u001b[39m     config_json = f.read()\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m model = \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m all_filenames = zf.namelist()\n\u001b[32m    447\u001b[39m extract_dir = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:431\u001b[39m, in \u001b[36m_model_from_config\u001b[39m\u001b[34m(config_json, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     model = \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:735\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    733\u001b[39m     instance = \u001b[38;5;28mcls\u001b[39m.from_config(inner_config)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    736\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m could not be deserialized properly. Please\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    737\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m ensure that components that are Python object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    738\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m instances (layers, models, etc.) returned by\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    739\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    740\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m model\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms `from_config()` method.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    741\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    742\u001b[39m     )\n\u001b[32m    743\u001b[39m build_config = config.get(\u001b[33m\"\u001b[39m\u001b[33mbuild_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m build_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m instance.built:\n",
      "\u001b[31mTypeError\u001b[39m: <class 'keras.src.models.functional.Functional'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'binary_crossentropy', 'loss_weights': None, 'metrics': [{'module': 'keras.metrics', 'class_name': 'AUC', 'config': {'name': 'auc', 'dtype': 'float32', 'num_thresholds': 200, 'curve': 'ROC', 'summation_method': 'interpolation', 'multi_label': False, 'num_labels': None, 'label_weights': None, 'from_logits': False}, 'registered_name': None}, {'module': 'builtins', 'class_name': 'function', 'config': 'Custom>brier', 'registered_name': 'function'}], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': False}}.\n\nException encountered: Could not locate class 'GraphMessagePassing'. Make sure custom classes and functions are decorated with `@keras.saving.register_keras_serializable()`. If they are already decorated, make sure they are all imported so that the decorator is run before trying to load them. Full object config: {'module': None, 'class_name': 'GraphMessagePassing', 'config': {'name': 'gnn_layer_0', 'hidden_dim': 32, 'dropout': 0.3, 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 128808718389504}}, 'registered_name': 'GraphMessagePassing', 'build_config': {'input_shape': [None, 14, 1]}, 'name': 'gnn_layer_0', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 14, 1], 'dtype': 'float32', 'keras_history': ['expand_dims', 0, 0]}}], 'kwargs': {}}]}"
     ]
    }
   ],
   "source": [
    "symbol = \"GOOG\"\n",
    "side, _ = await ML_Pipeline(build_gnn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43415fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 - 6s - 1s/step - auc: 0.5256 - brier: 0.2648 - loss: 0.7273 - val_auc: 0.4444 - val_brier: 0.2583 - val_loss: 0.7267\n",
      "Epoch 2/20\n",
      "4/4 - 0s - 53ms/step - auc: 0.4711 - brier: 0.2684 - loss: 0.7538 - val_auc: 0.4132 - val_brier: 0.2526 - val_loss: 0.7206\n",
      "Epoch 3/20\n",
      "4/4 - 0s - 50ms/step - auc: 0.4677 - brier: 0.2599 - loss: 0.7260 - val_auc: 0.2917 - val_brier: 0.2520 - val_loss: 0.7205\n",
      "Epoch 4/20\n",
      "4/4 - 0s - 45ms/step - auc: 0.4737 - brier: 0.2595 - loss: 0.7252 - val_auc: 0.3403 - val_brier: 0.2535 - val_loss: 0.7206\n",
      "Epoch 5/20\n",
      "4/4 - 0s - 45ms/step - auc: 0.5730 - brier: 0.2599 - loss: 0.6831 - val_auc: 0.3403 - val_brier: 0.2552 - val_loss: 0.7256\n",
      "Epoch 6/20\n",
      "4/4 - 0s - 52ms/step - auc: 0.5350 - brier: 0.2532 - loss: 0.6882 - val_auc: 0.3646 - val_brier: 0.2526 - val_loss: 0.7117\n",
      "Epoch 7/20\n",
      "4/4 - 0s - 49ms/step - auc: 0.5063 - brier: 0.2535 - loss: 0.6962 - val_auc: 0.3889 - val_brier: 0.2516 - val_loss: 0.7058\n",
      "Epoch 8/20\n",
      "4/4 - 0s - 53ms/step - auc: 0.5308 - brier: 0.2554 - loss: 0.6955 - val_auc: 0.3438 - val_brier: 0.2514 - val_loss: 0.7063\n",
      "Epoch 9/20\n",
      "4/4 - 0s - 52ms/step - auc: 0.4309 - brier: 0.2543 - loss: 0.7277 - val_auc: 0.3125 - val_brier: 0.2511 - val_loss: 0.7062\n",
      "Epoch 10/20\n",
      "4/4 - 0s - 49ms/step - auc: 0.5118 - brier: 0.2513 - loss: 0.7052 - val_auc: 0.3438 - val_brier: 0.2510 - val_loss: 0.7026\n",
      "Epoch 11/20\n",
      "4/4 - 0s - 46ms/step - auc: 0.5554 - brier: 0.2550 - loss: 0.6798 - val_auc: 0.3819 - val_brier: 0.2519 - val_loss: 0.7056\n",
      "Epoch 12/20\n",
      "4/4 - 0s - 48ms/step - auc: 0.5937 - brier: 0.2546 - loss: 0.6676 - val_auc: 0.3299 - val_brier: 0.2528 - val_loss: 0.7098\n",
      "Epoch 13/20\n",
      "4/4 - 0s - 48ms/step - auc: 0.5161 - brier: 0.2537 - loss: 0.7056 - val_auc: 0.4132 - val_brier: 0.2543 - val_loss: 0.7077\n",
      "Epoch 14/20\n",
      "4/4 - 0s - 48ms/step - auc: 0.5419 - brier: 0.2529 - loss: 0.6841 - val_auc: 0.5729 - val_brier: 0.2546 - val_loss: 0.6943\n",
      "Epoch 15/20\n",
      "4/4 - 0s - 48ms/step - auc: 0.5884 - brier: 0.2526 - loss: 0.6650 - val_auc: 0.6181 - val_brier: 0.2570 - val_loss: 0.6938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "AAPL: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"AAPL\"\n",
    "side, _ = await ML_Pipeline(build_gnn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ecf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 - 6s - 2s/step - auc: 0.5072 - brier: 0.2533 - loss: 0.7066 - val_auc: 0.6084 - val_brier: 0.2724 - val_loss: 0.7316\n",
      "Epoch 2/20\n",
      "4/4 - 0s - 51ms/step - auc: 0.5033 - brier: 0.2529 - loss: 0.7080 - val_auc: 0.3811 - val_brier: 0.2654 - val_loss: 0.7424\n",
      "Epoch 3/20\n",
      "4/4 - 0s - 52ms/step - auc: 0.5463 - brier: 0.2509 - loss: 0.6926 - val_auc: 0.3217 - val_brier: 0.2660 - val_loss: 0.7562\n",
      "Epoch 4/20\n",
      "4/4 - 0s - 47ms/step - auc: 0.5172 - brier: 0.2505 - loss: 0.6957 - val_auc: 0.3811 - val_brier: 0.2660 - val_loss: 0.7456\n",
      "Epoch 5/20\n",
      "4/4 - 0s - 54ms/step - auc: 0.4982 - brier: 0.2527 - loss: 0.7053 - val_auc: 0.3671 - val_brier: 0.2634 - val_loss: 0.7416\n",
      "Epoch 6/20\n",
      "4/4 - 0s - 47ms/step - auc: 0.5092 - brier: 0.2515 - loss: 0.6990 - val_auc: 0.3636 - val_brier: 0.2603 - val_loss: 0.7369\n",
      "Epoch 7/20\n",
      "4/4 - 0s - 45ms/step - auc: 0.5485 - brier: 0.2493 - loss: 0.6896 - val_auc: 0.3322 - val_brier: 0.2610 - val_loss: 0.7384\n",
      "Epoch 8/20\n",
      "4/4 - 0s - 48ms/step - auc: 0.5846 - brier: 0.2527 - loss: 0.6763 - val_auc: 0.2832 - val_brier: 0.2625 - val_loss: 0.7472\n",
      "Epoch 9/20\n",
      "4/4 - 0s - 44ms/step - auc: 0.5480 - brier: 0.2496 - loss: 0.6908 - val_auc: 0.3462 - val_brier: 0.2663 - val_loss: 0.7608\n",
      "Epoch 10/20\n",
      "4/4 - 0s - 48ms/step - auc: 0.5037 - brier: 0.2506 - loss: 0.7008 - val_auc: 0.3566 - val_brier: 0.2653 - val_loss: 0.7593\n",
      "Epoch 11/20\n",
      "4/4 - 0s - 46ms/step - auc: 0.5453 - brier: 0.2489 - loss: 0.6831 - val_auc: 0.3392 - val_brier: 0.2666 - val_loss: 0.7616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
      "MCFT: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"MCFT\"\n",
    "side, _ = await ML_Pipeline(build_gnn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb63759",
   "metadata": {},
   "source": [
    "### NAD-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 - 6s - 2s/step - auc: 0.4857 - brier: 0.3144 - loss: 1.1973 - val_auc: 0.3951 - val_brier: 0.2627 - val_loss: 0.8122\n",
      "Epoch 2/20\n",
      "4/4 - 0s - 48ms/step - auc: 0.5802 - brier: 0.2913 - loss: 0.9853 - val_auc: 0.3811 - val_brier: 0.2577 - val_loss: 0.7822\n",
      "Epoch 3/20\n",
      "4/4 - 0s - 45ms/step - auc: 0.6068 - brier: 0.2762 - loss: 0.8772 - val_auc: 0.3287 - val_brier: 0.2539 - val_loss: 0.7592\n",
      "Epoch 4/20\n",
      "4/4 - 0s - 44ms/step - auc: 0.5606 - brier: 0.2701 - loss: 0.8792 - val_auc: 0.2692 - val_brier: 0.2518 - val_loss: 0.7437\n",
      "Epoch 5/20\n",
      "4/4 - 0s - 44ms/step - auc: 0.5859 - brier: 0.2743 - loss: 0.8535 - val_auc: 0.2587 - val_brier: 0.2514 - val_loss: 0.7369\n",
      "Epoch 6/20\n",
      "4/4 - 0s - 45ms/step - auc: 0.5572 - brier: 0.2785 - loss: 0.8891 - val_auc: 0.3007 - val_brier: 0.2520 - val_loss: 0.7318\n",
      "Epoch 7/20\n",
      "4/4 - 0s - 51ms/step - auc: 0.5331 - brier: 0.2726 - loss: 0.8784 - val_auc: 0.2762 - val_brier: 0.2534 - val_loss: 0.7296\n",
      "Epoch 8/20\n",
      "4/4 - 0s - 48ms/step - auc: 0.5980 - brier: 0.2676 - loss: 0.8221 - val_auc: 0.3007 - val_brier: 0.2548 - val_loss: 0.7295\n",
      "Epoch 9/20\n",
      "4/4 - 0s - 48ms/step - auc: 0.5369 - brier: 0.2682 - loss: 0.8451 - val_auc: 0.2657 - val_brier: 0.2569 - val_loss: 0.7320\n",
      "Epoch 10/20\n",
      "4/4 - 0s - 45ms/step - auc: 0.5080 - brier: 0.2650 - loss: 0.8500 - val_auc: 0.3007 - val_brier: 0.2589 - val_loss: 0.7325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "\nObject AutoencoderClassifierLite was created by passing\nnon-serializable argument values in `__init__()`,\nand therefore the object must override `get_config()` in\norder to be serializable. Please implement `get_config()`.\n\nExample:\n\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2, **kwargs):\n        super().__init__(**kwargs)\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m symbol = \u001b[33m\"\u001b[39m\u001b[33mGOOG\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m side, _ = \u001b[38;5;28;01mawait\u001b[39;00m ML_Pipeline(build_autoencoder_classifier_lite, symbol, {})\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mside\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/src/live_trader/ml_model/training.py:232\u001b[39m, in \u001b[36mML_Pipeline\u001b[39m\u001b[34m(model_builder, symbol, position_data)\u001b[39m\n\u001b[32m    229\u001b[39m     auc_roc, f1 = evaluate_model(model, symbol, X_test, y_test)\n\u001b[32m    231\u001b[39m     joblib.dump(scaler, SCALER_PATH)\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Fetching mdip data till today (realtime data)\u001b[39;00m\n\u001b[32m    236\u001b[39m hist_df = fetch_data(symbol = symbol, \n\u001b[32m    237\u001b[39m                     start_date = (mdip.year, mdip.month, mdip.day), \n\u001b[32m    238\u001b[39m                     end_date = (yesterday.year, yesterday.month, yesterday.day))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py:268\u001b[39m, in \u001b[36mOperation.get_config\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    252\u001b[39m         textwrap.dedent(\n\u001b[32m    253\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    265\u001b[39m         )\n\u001b[32m    266\u001b[39m     )\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    269\u001b[39m         textwrap.dedent(\n\u001b[32m    270\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[33mObject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m was created by passing\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[33mnon-serializable argument values in `__init__()`,\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[33mand therefore the object must override `get_config()` in\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[33morder to be serializable. Please implement `get_config()`.\u001b[39m\n\u001b[32m    275\u001b[39m \n\u001b[32m    276\u001b[39m \u001b[33mExample:\u001b[39m\n\u001b[32m    277\u001b[39m \n\u001b[32m    278\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    279\u001b[39m         )\n\u001b[32m    280\u001b[39m     )\n",
      "\u001b[31mNotImplementedError\u001b[39m: \nObject AutoencoderClassifierLite was created by passing\nnon-serializable argument values in `__init__()`,\nand therefore the object must override `get_config()` in\norder to be serializable. Please implement `get_config()`.\n\nExample:\n\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2, **kwargs):\n        super().__init__(**kwargs)\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config\n"
     ]
    }
   ],
   "source": [
    "symbol = \"GOOG\"\n",
    "side, _ = await ML_Pipeline(build_autoencoder_classifier_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d0ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
      "AAPL: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"AAPL\"\n",
    "side, _ = await ML_Pipeline(build_autoencoder_classifier_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5426ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "MCFT: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"MCFT\"\n",
    "side, _ = await ML_Pipeline(build_autoencoder_classifier_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49059176",
   "metadata": {},
   "source": [
    "### CNN-GRU lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c7255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
      "GOOG: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "symbol = \"GOOG\"\n",
    "side, _ = await ML_Pipeline(build_cnn_gru_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9862cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "AAPL: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"AAPL\"\n",
    "side, _ = await ML_Pipeline(build_cnn_gru_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07166dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
      "MCFT: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"MCFT\"\n",
    "side, _ = await ML_Pipeline(build_cnn_gru_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
