{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce012550",
   "metadata": {},
   "source": [
    "# Model Experimenting\n",
    "This notebook will work as an experiment on how well different ML models do on historical data for different stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f308b",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813ca6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "from live_trader.ml_model import ML_Pipeline\n",
    "from live_trader.ml_model.ml_strategies import AI_strategy, attention_bilstm_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "791a8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, Bidirectional,\n",
    "    Attention, LayerNormalization, Add, GlobalAveragePooling1D, \n",
    "    Conv1D, MultiHeadAttention, Reshape, Lambda\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, F1Score\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e2a44",
   "metadata": {},
   "source": [
    "## Testing our models that are already made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d48ec8",
   "metadata": {},
   "source": [
    "### Basic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0f066c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 2s - 17ms/step - loss: 0.6932 - roc_auc: 0.5130 - val_loss: 0.6953 - val_roc_auc: 0.5601\n",
      "Epoch 2/20\n",
      "108/108 - 0s - 4ms/step - loss: 0.6930 - roc_auc: 0.5217 - val_loss: 0.6927 - val_roc_auc: 0.5531\n",
      "Epoch 3/20\n",
      "108/108 - 0s - 4ms/step - loss: 0.6910 - roc_auc: 0.5291 - val_loss: 0.7063 - val_roc_auc: 0.5623\n",
      "Epoch 4/20\n",
      "108/108 - 0s - 4ms/step - loss: 0.6917 - roc_auc: 0.5201 - val_loss: 0.6965 - val_roc_auc: 0.5609\n",
      "Epoch 5/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6908 - roc_auc: 0.5203 - val_loss: 0.6999 - val_roc_auc: 0.5679\n",
      "Epoch 6/20\n",
      "108/108 - 0s - 4ms/step - loss: 0.6879 - roc_auc: 0.5383 - val_loss: 0.7028 - val_roc_auc: 0.5682\n",
      "Epoch 7/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6886 - roc_auc: 0.5349 - val_loss: 0.6918 - val_roc_auc: 0.5691\n",
      "Epoch 8/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6881 - roc_auc: 0.5383 - val_loss: 0.6893 - val_roc_auc: 0.5650\n",
      "Epoch 9/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6857 - roc_auc: 0.5471 - val_loss: 0.6894 - val_roc_auc: 0.5668\n",
      "Epoch 10/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6878 - roc_auc: 0.5366 - val_loss: 0.7125 - val_roc_auc: 0.5668\n",
      "Epoch 11/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6865 - roc_auc: 0.5362 - val_loss: 0.6965 - val_roc_auc: 0.5686\n",
      "Epoch 12/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6865 - roc_auc: 0.5423 - val_loss: 0.7229 - val_roc_auc: 0.5633\n",
      "Epoch 13/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6856 - roc_auc: 0.5459 - val_loss: 0.6955 - val_roc_auc: 0.5663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "GOOG: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "side, _ = await AI_strategy(\"GOOG\")\n",
    "print(f\"GOOG: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92953d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 2s - 16ms/step - loss: 0.6965 - roc_auc: 0.5105 - val_loss: 0.6918 - val_roc_auc: 0.5013\n",
      "Epoch 2/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6955 - roc_auc: 0.5125 - val_loss: 0.6937 - val_roc_auc: 0.4937\n",
      "Epoch 3/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6923 - roc_auc: 0.5328 - val_loss: 0.6919 - val_roc_auc: 0.5117\n",
      "Epoch 4/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6920 - roc_auc: 0.5274 - val_loss: 0.6942 - val_roc_auc: 0.4830\n",
      "Epoch 5/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6907 - roc_auc: 0.5312 - val_loss: 0.6974 - val_roc_auc: 0.4668\n",
      "Epoch 6/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6896 - roc_auc: 0.5381 - val_loss: 0.6969 - val_roc_auc: 0.4550\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "AAPL: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "side, _ = await AI_strategy(\"AAPL\")\n",
    "print(f\"AAPL: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e189c9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 2s - 16ms/step - loss: 0.6973 - roc_auc: 0.5203 - val_loss: 0.6968 - val_roc_auc: 0.4907\n",
      "Epoch 2/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6951 - roc_auc: 0.5220 - val_loss: 0.6969 - val_roc_auc: 0.4929\n",
      "Epoch 3/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6900 - roc_auc: 0.5434 - val_loss: 0.7079 - val_roc_auc: 0.4946\n",
      "Epoch 4/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6895 - roc_auc: 0.5507 - val_loss: 0.7015 - val_roc_auc: 0.5043\n",
      "Epoch 5/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6857 - roc_auc: 0.5635 - val_loss: 0.7089 - val_roc_auc: 0.5087\n",
      "Epoch 6/20\n",
      "108/108 - 0s - 3ms/step - loss: 0.6874 - roc_auc: 0.5512 - val_loss: 0.7042 - val_roc_auc: 0.5110\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "MCFT: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "side, _ = await AI_strategy(\"MCFT\")\n",
    "print(f\"MCFT: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb762ce",
   "metadata": {},
   "source": [
    "### attention bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76bc9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 3s - 31ms/step - loss: 0.7540 - roc_auc: 0.4970 - val_loss: 0.6964 - val_roc_auc: 0.4914\n",
      "Epoch 2/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.7200 - roc_auc: 0.4685 - val_loss: 0.6996 - val_roc_auc: 0.5592\n",
      "Epoch 3/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6984 - roc_auc: 0.5130 - val_loss: 0.6982 - val_roc_auc: 0.5583\n",
      "Epoch 4/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6973 - roc_auc: 0.5104 - val_loss: 0.8853 - val_roc_auc: 0.5571\n",
      "Epoch 5/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6932 - roc_auc: 0.5238 - val_loss: 0.7036 - val_roc_auc: 0.5572\n",
      "Epoch 6/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6947 - roc_auc: 0.5101 - val_loss: 0.8638 - val_roc_auc: 0.5591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "GOOG: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "side, _ = await attention_bilstm_strategy(\"GOOG\")\n",
    "print(f\"GOOG: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07527cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 3s - 31ms/step - loss: 0.7670 - roc_auc: 0.4908 - val_loss: 0.7568 - val_roc_auc: 0.4560\n",
      "Epoch 2/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.7134 - roc_auc: 0.5197 - val_loss: 0.7098 - val_roc_auc: 0.4745\n",
      "Epoch 3/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.7006 - roc_auc: 0.5341 - val_loss: 0.7442 - val_roc_auc: 0.4757\n",
      "Epoch 4/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.7014 - roc_auc: 0.4959 - val_loss: 0.6919 - val_roc_auc: 0.5632\n",
      "Epoch 5/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6962 - roc_auc: 0.5200 - val_loss: 0.7044 - val_roc_auc: 0.4876\n",
      "Epoch 6/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6912 - roc_auc: 0.5410 - val_loss: 0.6958 - val_roc_auc: 0.5215\n",
      "Epoch 7/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6937 - roc_auc: 0.5291 - val_loss: 0.7180 - val_roc_auc: 0.5058\n",
      "Epoch 8/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6918 - roc_auc: 0.5447 - val_loss: 0.7205 - val_roc_auc: 0.5070\n",
      "Epoch 9/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6896 - roc_auc: 0.5381 - val_loss: 0.7062 - val_roc_auc: 0.4984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "AAPL: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "side, _ = await attention_bilstm_strategy(\"AAPL\")\n",
    "print(f\"AAPL: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0630e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 3s - 31ms/step - loss: 0.7501 - roc_auc: 0.5096 - val_loss: 0.7235 - val_roc_auc: 0.5133\n",
      "Epoch 2/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.7087 - roc_auc: 0.5237 - val_loss: 0.7243 - val_roc_auc: 0.5172\n",
      "Epoch 3/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.7015 - roc_auc: 0.5243 - val_loss: 0.7347 - val_roc_auc: 0.4913\n",
      "Epoch 4/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6984 - roc_auc: 0.5372 - val_loss: 0.7152 - val_roc_auc: 0.4917\n",
      "Epoch 5/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6909 - roc_auc: 0.5543 - val_loss: 0.7101 - val_roc_auc: 0.5070\n",
      "Epoch 6/20\n",
      "108/108 - 1s - 6ms/step - loss: 0.6866 - roc_auc: 0.5625 - val_loss: 0.7106 - val_roc_auc: 0.4965\n",
      "Epoch 7/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6862 - roc_auc: 0.5595 - val_loss: 0.7185 - val_roc_auc: 0.5104\n",
      "Epoch 8/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6836 - roc_auc: 0.5668 - val_loss: 0.7065 - val_roc_auc: 0.5306\n",
      "Epoch 9/20\n",
      "108/108 - 1s - 6ms/step - loss: 0.6867 - roc_auc: 0.5583 - val_loss: 0.7178 - val_roc_auc: 0.5061\n",
      "Epoch 10/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6825 - roc_auc: 0.5829 - val_loss: 0.7290 - val_roc_auc: 0.5237\n",
      "Epoch 11/20\n",
      "108/108 - 1s - 6ms/step - loss: 0.6872 - roc_auc: 0.5665 - val_loss: 0.7039 - val_roc_auc: 0.5333\n",
      "Epoch 12/20\n",
      "108/108 - 1s - 6ms/step - loss: 0.6803 - roc_auc: 0.5639 - val_loss: 0.7281 - val_roc_auc: 0.5282\n",
      "Epoch 13/20\n",
      "108/108 - 1s - 5ms/step - loss: 0.6795 - roc_auc: 0.5787 - val_loss: 0.7143 - val_roc_auc: 0.5200\n",
      "Epoch 14/20\n",
      "108/108 - 1s - 6ms/step - loss: 0.6817 - roc_auc: 0.5757 - val_loss: 0.7268 - val_roc_auc: 0.5207\n",
      "Epoch 15/20\n",
      "108/108 - 1s - 6ms/step - loss: 0.6777 - roc_auc: 0.5835 - val_loss: 0.7298 - val_roc_auc: 0.4968\n",
      "Epoch 16/20\n",
      "108/108 - 1s - 6ms/step - loss: 0.6821 - roc_auc: 0.5785 - val_loss: 0.7189 - val_roc_auc: 0.5111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "MCFT: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "side, _ = await attention_bilstm_strategy(\"MCFT\")\n",
    "print(f\"MCFT: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f0a9b",
   "metadata": {},
   "source": [
    "Both attention_bilstm and basic_lstm are not good models. Therefore, we will try out other models as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414af5d",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef95a1",
   "metadata": {},
   "source": [
    "### Testing out Temporal Convolutional Network (TCN-lite)\n",
    "- learns local temporal patterns\n",
    "- no reccurence (more stable)\n",
    "- strong inductibe bias for noisy sequences\n",
    "- much easier to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6abb39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tcn_lite(X_train_seq: Union[np.ndarray, list]) -> Model:\n",
    "    \"\"\"\n",
    "    Builds a lightweight Temporal Convolutional Network (TCN-style)\n",
    "    for noisy financial time series classification.\n",
    "\n",
    "    Designed to be robust to non-stationarity and overfitting.\n",
    "\n",
    "    Args:\n",
    "        X_train_seq (array-like):\n",
    "            Training sequences of shape (n_samples, time_steps, n_features)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras Model\n",
    "    \"\"\"\n",
    "    n_features = X_train_seq.shape[2]\n",
    "\n",
    "    inputs = Input(shape=(None, n_features))\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"causal\",\n",
    "        activation=\"relu\"\n",
    "    )(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=16,\n",
    "        kernel_size=3,\n",
    "        padding=\"causal\",\n",
    "        activation=\"relu\"\n",
    "    )(x)\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"tcn_lite\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            AUC(name=\"auc\"),\n",
    "            \"precision\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85265e6a",
   "metadata": {},
   "source": [
    "### PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffca0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_patchtst_lite(\n",
    "    X_train_seq: Union[np.ndarray, list],\n",
    "    patch_len: int = 16,\n",
    "    d_model: int = 64,\n",
    "    num_heads: int = 4,\n",
    "    ff_dim: int = 128,\n",
    "    dropout: float = 0.3\n",
    ") -> Model:\n",
    "    \"\"\"\n",
    "    Builds a lightweight PatchTST-style Transformer model for\n",
    "    noisy financial time series classification.\n",
    "\n",
    "    The model splits the time dimension into patches, embeds them,\n",
    "    and applies a Transformer encoder for temporal modeling.\n",
    "\n",
    "    Designed for robustness to non-stationarity and overfitting.\n",
    "\n",
    "    Args:\n",
    "        X_train_seq (array-like):\n",
    "            Training sequences of shape (n_samples, time_steps, n_features)\n",
    "\n",
    "        patch_len (int):\n",
    "            Length of each temporal patch\n",
    "\n",
    "        d_model (int):\n",
    "            Transformer embedding dimension\n",
    "\n",
    "        num_heads (int):\n",
    "            Number of attention heads\n",
    "\n",
    "        ff_dim (int):\n",
    "            Feed-forward network size inside Transformer\n",
    "\n",
    "        dropout (float):\n",
    "            Dropout rate\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras Model\n",
    "    \"\"\"\n",
    "\n",
    "    n_features = X_train_seq.shape[2]\n",
    "\n",
    "    inputs = Input(shape=(None, n_features))\n",
    "\n",
    "    # ---- Patch embedding ----\n",
    "    # Split time dimension into non-overlapping patches\n",
    "    def patchify(x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        time_steps = tf.shape(x)[1]\n",
    "\n",
    "        # Ensure at least one patch\n",
    "        pad_len = tf.maximum(0, patch_len - time_steps)\n",
    "        x = tf.pad(x, [[0, 0], [0, pad_len], [0, 0]])\n",
    "\n",
    "        # Recompute after padding\n",
    "        time_steps = tf.shape(x)[1]\n",
    "        n_patches = time_steps // patch_len\n",
    "\n",
    "        x = x[:, :n_patches * patch_len, :]\n",
    "        x = tf.reshape(x, (batch_size, n_patches, patch_len * n_features))\n",
    "        return x\n",
    "\n",
    "    x = tf.keras.layers.Lambda(patchify, name=\"patchify\")(inputs)\n",
    "\n",
    "    x = Dense(d_model, activation=\"linear\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    # ---- Transformer Encoder Block ----\n",
    "    attn_out = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model // num_heads,\n",
    "        dropout=dropout\n",
    "    )(x, x)\n",
    "\n",
    "    x = LayerNormalization()(x + attn_out)\n",
    "\n",
    "    ff_out = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    ff_out = Dropout(dropout)(ff_out)\n",
    "    ff_out = Dense(d_model)(ff_out)\n",
    "\n",
    "    x = LayerNormalization()(x + ff_out)\n",
    "\n",
    "    # ---- Pooling & Head ----\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"patchtst_lite\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            AUC(name=\"auc\"),\n",
    "        ],\n",
    "        run_eagerly=True\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ba0a3",
   "metadata": {},
   "source": [
    "### GNN (Graph-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ce67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMessagePassing(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Simple graph message-passing layer with learned adjacency.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim: int, dropout: float = 0.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape: (B, N_nodes, D)\n",
    "        n_nodes = input_shape[1]\n",
    "\n",
    "        self.adjacency = Dense(\n",
    "            n_nodes,\n",
    "            activation=\"tanh\",\n",
    "            name=\"learned_adjacency\"\n",
    "        )\n",
    "        self.node_update = Dense(self.hidden_dim, activation=\"relu\")\n",
    "        self.norm = LayerNormalization()\n",
    "        self.drop = Dropout(self.dropout)\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # x: (B, N, D)\n",
    "        A = self.adjacency(x)          # (B, N, N)\n",
    "        messages = tf.matmul(A, x)    # (B, N, D)\n",
    "        x = self.node_update(messages)\n",
    "        x = self.norm(x)\n",
    "        return self.drop(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cf3ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gnn_lite(\n",
    "    X_train_seq: Union[np.ndarray, list],\n",
    "    hidden_dim: int = 32,\n",
    "    gnn_layers: int = 2,\n",
    "    dropout: float = 0.3\n",
    ") -> Model:\n",
    "    \"\"\"\n",
    "    Builds a lightweight Graph Neural Network (GNN-style) model\n",
    "    for noisy financial time series classification.\n",
    "\n",
    "    Nodes represent features (indicators).\n",
    "    Edges are learned implicitly via feature interactions.\n",
    "\n",
    "    Designed for robustness to:\n",
    "    - Non-stationarity\n",
    "    - Variable-length sequences\n",
    "    - Small batch sizes\n",
    "\n",
    "    Args:\n",
    "        X_train_seq (array-like):\n",
    "            Training sequences of shape (n_samples, time_steps, n_features)\n",
    "\n",
    "        hidden_dim (int):\n",
    "            Node embedding dimension\n",
    "\n",
    "        gnn_layers (int):\n",
    "            Number of graph message-passing layers\n",
    "\n",
    "        dropout (float):\n",
    "            Dropout rate\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras Model\n",
    "    \"\"\"\n",
    "\n",
    "    n_features = X_train_seq.shape[2]\n",
    "\n",
    "    inputs = Input(shape=(None, n_features))\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Temporal aggregation\n",
    "    # --------------------------------------------------\n",
    "    # (B, T, F) → (B, F)\n",
    "    x = GlobalAveragePooling1D(name=\"temporal_pool\")(inputs)\n",
    "\n",
    "    # Treat features as nodes\n",
    "    # (B, F) → (B, F, 1)\n",
    "    x = Lambda(lambda t: tf.expand_dims(t, axis=-1))(x)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # GNN layers\n",
    "    # --------------------------------------------------\n",
    "    for i in range(gnn_layers):\n",
    "        x = GraphMessagePassing(\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            name=f\"gnn_layer_{i}\"\n",
    "        )(x)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Graph pooling\n",
    "    # --------------------------------------------------\n",
    "    x = Lambda(lambda t: tf.reduce_mean(t, axis=1))(x)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Head\n",
    "    # --------------------------------------------------\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"gnn_lite\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[AUC(name=\"auc\")],\n",
    "        run_eagerly=True\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb8d0e",
   "metadata": {},
   "source": [
    "### Neural Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f46ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import ops\n",
    "\n",
    "\n",
    "class AutoencoderClassifierLite(keras.Model):\n",
    "    \"\"\"\n",
    "    Autoencoder + Classifier with internal reconstruction loss.\n",
    "\n",
    "    Keras 3–safe implementation using subclassed Model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        latent_dim: int = 16,\n",
    "        hidden_dim: int = 64,\n",
    "        dropout: float = 0.3,\n",
    "        recon_weight: float = 0.3,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.recon_weight = recon_weight\n",
    "\n",
    "        # -------- Pooling --------\n",
    "        self.pool = GlobalAveragePooling1D()\n",
    "\n",
    "        # -------- Encoder --------\n",
    "        self.enc_dense = Dense(hidden_dim, activation=\"relu\")\n",
    "        self.enc_norm = LayerNormalization()\n",
    "        self.enc_drop = Dropout(dropout)\n",
    "        self.latent = Dense(latent_dim, activation=\"linear\")\n",
    "\n",
    "        # -------- Decoder --------\n",
    "        self.dec_dense = Dense(hidden_dim, activation=\"relu\")\n",
    "        self.dec_drop = Dropout(dropout)\n",
    "        self.reconstruction = Dense(n_features, activation=\"linear\")\n",
    "\n",
    "        # -------- Classifier --------\n",
    "        self.cls_dense = Dense(32, activation=\"relu\")\n",
    "        self.cls_drop = Dropout(dropout)\n",
    "        self.output_head = Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # -------------------------\n",
    "        # Pool input\n",
    "        # -------------------------\n",
    "        pooled = self.pool(inputs)\n",
    "\n",
    "        # -------------------------\n",
    "        # Encode\n",
    "        # -------------------------\n",
    "        x = self.enc_dense(pooled)\n",
    "        x = self.enc_norm(x)\n",
    "        x = self.enc_drop(x, training=training)\n",
    "\n",
    "        latent = self.latent(x)\n",
    "\n",
    "        # -------------------------\n",
    "        # Decode (reconstruction)\n",
    "        # -------------------------\n",
    "        d = self.dec_dense(latent)\n",
    "        d = self.dec_drop(d, training=training)\n",
    "        recon = self.reconstruction(d)\n",
    "\n",
    "        # -------------------------\n",
    "        # Reconstruction loss\n",
    "        # -------------------------\n",
    "        diff = pooled - recon\n",
    "        recon_loss = ops.mean(ops.square(diff))\n",
    "        self.add_loss(self.recon_weight * recon_loss)\n",
    "\n",
    "        # -------------------------\n",
    "        # Classification\n",
    "        # -------------------------\n",
    "        c = self.cls_dense(latent)\n",
    "        c = self.cls_drop(c, training=training)\n",
    "        return self.output_head(c)\n",
    "\n",
    "\n",
    "def build_autoencoder_classifier_lite(\n",
    "    X_train_seq: Union[np.ndarray, list],\n",
    "    latent_dim: int = 16,\n",
    "    hidden_dim: int = 64,\n",
    "    dropout: float = 0.3,\n",
    "    recon_weight: float = 0.3\n",
    ") -> keras.Model:\n",
    "    \"\"\"\n",
    "    Builds an Autoencoder + Classifier model for\n",
    "    neural anomaly detection in time series.\n",
    "\n",
    "    Fully compatible with Keras 3 and existing pipelines.\n",
    "    \"\"\"\n",
    "\n",
    "    n_features = X_train_seq.shape[2]\n",
    "\n",
    "    model = AutoencoderClassifierLite(\n",
    "        n_features=n_features,\n",
    "        latent_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        dropout=dropout,\n",
    "        recon_weight=recon_weight,\n",
    "        name=\"autoencoder_classifier_lite\"\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[AUC(name=\"auc\")]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64087c52",
   "metadata": {},
   "source": [
    "## Training / Testing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ee13a",
   "metadata": {},
   "source": [
    "### TCN-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45b32b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 2s - 20ms/step - auc: 0.5008 - loss: 0.7260 - precision: 0.5466 - val_auc: 0.5032 - val_loss: 0.7252 - val_precision: 0.2000\n",
      "Epoch 2/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5054 - loss: 0.6982 - precision: 0.5347 - val_auc: 0.5019 - val_loss: 0.7213 - val_precision: 0.4444\n",
      "Epoch 3/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5091 - loss: 0.6952 - precision: 0.5396 - val_auc: 0.5157 - val_loss: 0.7057 - val_precision: 0.6154\n",
      "Epoch 4/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.4933 - loss: 0.6971 - precision: 0.5393 - val_auc: 0.5409 - val_loss: 0.6936 - val_precision: 0.5682\n",
      "Epoch 5/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5058 - loss: 0.6946 - precision: 0.5415 - val_auc: 0.5220 - val_loss: 0.7082 - val_precision: 0.5714\n",
      "Epoch 6/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5129 - loss: 0.6930 - precision: 0.5446 - val_auc: 0.5208 - val_loss: 0.7226 - val_precision: 0.0000e+00\n",
      "Epoch 7/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5059 - loss: 0.6934 - precision: 0.5466 - val_auc: 0.5259 - val_loss: 0.6979 - val_precision: 0.6250\n",
      "Epoch 8/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5263 - loss: 0.6890 - precision: 0.5475 - val_auc: 0.5222 - val_loss: 0.7069 - val_precision: 1.0000\n",
      "Epoch 9/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5155 - loss: 0.6912 - precision: 0.5458 - val_auc: 0.5268 - val_loss: 0.7066 - val_precision: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "GOOG: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "symbol = \"GOOG\"\n",
    "side, _ = await ML_Pipeline(build_tcn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "142a1356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 2s - 22ms/step - auc: 0.5167 - loss: 0.7077 - precision: 0.5448 - val_auc: 0.4567 - val_loss: 0.7240 - val_precision: 0.5510\n",
      "Epoch 2/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5304 - loss: 0.6986 - precision: 0.5498 - val_auc: 0.4311 - val_loss: 0.7249 - val_precision: 0.5000\n",
      "Epoch 3/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5276 - loss: 0.6959 - precision: 0.5469 - val_auc: 0.4789 - val_loss: 0.7013 - val_precision: 0.5487\n",
      "Epoch 4/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5289 - loss: 0.6936 - precision: 0.5483 - val_auc: 0.4533 - val_loss: 0.7098 - val_precision: 0.4727\n",
      "Epoch 5/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5497 - loss: 0.6876 - precision: 0.5528 - val_auc: 0.4707 - val_loss: 0.7005 - val_precision: 0.5397\n",
      "Epoch 6/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5310 - loss: 0.6908 - precision: 0.5482 - val_auc: 0.4800 - val_loss: 0.6980 - val_precision: 0.4944\n",
      "Epoch 7/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5488 - loss: 0.6875 - precision: 0.5719 - val_auc: 0.4641 - val_loss: 0.7034 - val_precision: 0.5155\n",
      "Epoch 8/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5422 - loss: 0.6888 - precision: 0.5545 - val_auc: 0.4553 - val_loss: 0.7096 - val_precision: 0.5500\n",
      "Epoch 9/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5485 - loss: 0.6866 - precision: 0.5598 - val_auc: 0.4848 - val_loss: 0.7117 - val_precision: 0.5800\n",
      "Epoch 10/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5515 - loss: 0.6868 - precision: 0.5528 - val_auc: 0.4687 - val_loss: 0.7072 - val_precision: 0.5357\n",
      "Epoch 11/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5499 - loss: 0.6877 - precision: 0.5595 - val_auc: 0.4852 - val_loss: 0.7019 - val_precision: 0.5413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "AAPL: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "symbol = \"AAPL\"\n",
    "side, _ = await ML_Pipeline(build_tcn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c48343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 3s - 25ms/step - auc: 0.5073 - loss: 0.7123 - precision: 0.5249 - val_auc: 0.5243 - val_loss: 0.6925 - val_precision: 0.4921\n",
      "Epoch 2/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.4975 - loss: 0.7031 - precision: 0.5205 - val_auc: 0.5537 - val_loss: 0.6886 - val_precision: 0.6429\n",
      "Epoch 3/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5341 - loss: 0.6920 - precision: 0.5387 - val_auc: 0.5180 - val_loss: 0.6913 - val_precision: 0.4444\n",
      "Epoch 4/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5236 - loss: 0.6943 - precision: 0.5287 - val_auc: 0.5477 - val_loss: 0.6921 - val_precision: 0.4000\n",
      "Epoch 5/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5394 - loss: 0.6916 - precision: 0.5470 - val_auc: 0.5159 - val_loss: 0.6949 - val_precision: 0.4444\n",
      "Epoch 6/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5418 - loss: 0.6898 - precision: 0.5441 - val_auc: 0.5468 - val_loss: 0.6909 - val_precision: 0.5385\n",
      "Epoch 7/20\n",
      "108/108 - 0s - 3ms/step - auc: 0.5294 - loss: 0.6907 - precision: 0.5312 - val_auc: 0.5068 - val_loss: 0.6923 - val_precision: 0.4792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "MCFT: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"MCFT\"\n",
    "side, _ = await ML_Pipeline(build_tcn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a82f6",
   "metadata": {},
   "source": [
    "### PathTST-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a4c4db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (16, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (14, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 13s - 120ms/step - auc: 0.5017 - loss: 0.7249 - val_auc: 0.4749 - val_loss: 0.7008\n",
      "Epoch 2/20\n",
      "108/108 - 13s - 119ms/step - auc: 0.5057 - loss: 0.6974 - val_auc: 0.5198 - val_loss: 0.7053\n",
      "Epoch 3/20\n",
      "108/108 - 13s - 118ms/step - auc: 0.5054 - loss: 0.6941 - val_auc: 0.5390 - val_loss: 0.6964\n",
      "Epoch 4/20\n",
      "108/108 - 13s - 117ms/step - auc: 0.5109 - loss: 0.6918 - val_auc: 0.5380 - val_loss: 0.6935\n",
      "Epoch 5/20\n",
      "108/108 - 12s - 115ms/step - auc: 0.4958 - loss: 0.6901 - val_auc: 0.5555 - val_loss: 0.6996\n",
      "Epoch 6/20\n",
      "108/108 - 13s - 119ms/step - auc: 0.5167 - loss: 0.6922 - val_auc: 0.5522 - val_loss: 0.6918\n",
      "Epoch 7/20\n",
      "108/108 - 13s - 116ms/step - auc: 0.5407 - loss: 0.6867 - val_auc: 0.5637 - val_loss: 0.6921\n",
      "Epoch 8/20\n",
      "108/108 - 13s - 119ms/step - auc: 0.5233 - loss: 0.6889 - val_auc: 0.5550 - val_loss: 0.6969\n",
      "Epoch 9/20\n",
      "108/108 - 13s - 119ms/step - auc: 0.5312 - loss: 0.6882 - val_auc: 0.5516 - val_loss: 0.7176\n",
      "Epoch 10/20\n",
      "108/108 - 13s - 116ms/step - auc: 0.5254 - loss: 0.6888 - val_auc: 0.5307 - val_loss: 0.6982\n",
      "Epoch 11/20\n",
      "108/108 - 13s - 117ms/step - auc: 0.5283 - loss: 0.6889 - val_auc: 0.5435 - val_loss: 0.6971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (32, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "GOOG: SideSignal.HOLD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "symbol = \"GOOG\"\n",
    "side, _ = await ML_Pipeline(build_patchtst_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d4e4723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (16, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (14, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 13s - 119ms/step - auc: 0.4728 - loss: 0.7478 - val_auc: 0.3951 - val_loss: 0.7312\n",
      "Epoch 2/20\n",
      "108/108 - 12s - 113ms/step - auc: 0.5207 - loss: 0.6992 - val_auc: 0.5003 - val_loss: 0.6917\n",
      "Epoch 3/20\n",
      "108/108 - 12s - 114ms/step - auc: 0.4910 - loss: 0.6952 - val_auc: 0.4802 - val_loss: 0.6933\n",
      "Epoch 4/20\n",
      "108/108 - 13s - 118ms/step - auc: 0.5076 - loss: 0.6924 - val_auc: 0.5269 - val_loss: 0.6892\n",
      "Epoch 5/20\n",
      "108/108 - 14s - 133ms/step - auc: 0.5476 - loss: 0.6878 - val_auc: 0.4739 - val_loss: 0.6922\n",
      "Epoch 6/20\n",
      "108/108 - 13s - 118ms/step - auc: 0.5068 - loss: 0.6922 - val_auc: 0.5558 - val_loss: 0.6878\n",
      "Epoch 7/20\n",
      "108/108 - 13s - 120ms/step - auc: 0.5432 - loss: 0.6883 - val_auc: 0.5083 - val_loss: 0.6931\n",
      "Epoch 8/20\n",
      "108/108 - 13s - 120ms/step - auc: 0.5180 - loss: 0.6904 - val_auc: 0.5606 - val_loss: 0.6914\n",
      "Epoch 9/20\n",
      "108/108 - 13s - 121ms/step - auc: 0.5295 - loss: 0.6903 - val_auc: 0.5420 - val_loss: 0.6876\n",
      "Epoch 10/20\n",
      "108/108 - 14s - 125ms/step - auc: 0.5358 - loss: 0.6879 - val_auc: 0.4800 - val_loss: 0.6984\n",
      "Epoch 11/20\n",
      "108/108 - 13s - 119ms/step - auc: 0.5355 - loss: 0.6882 - val_auc: 0.4695 - val_loss: 0.6918\n",
      "Epoch 12/20\n",
      "108/108 - 12s - 112ms/step - auc: 0.5591 - loss: 0.6841 - val_auc: 0.4706 - val_loss: 0.7065\n",
      "Epoch 13/20\n",
      "108/108 - 12s - 113ms/step - auc: 0.5486 - loss: 0.6860 - val_auc: 0.5310 - val_loss: 0.7025\n",
      "Epoch 14/20\n",
      "108/108 - 13s - 117ms/step - auc: 0.5429 - loss: 0.6863 - val_auc: 0.5273 - val_loss: 0.6974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (32, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "AAPL: SideSignal.BUY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "symbol = \"AAPL\"\n",
    "side, _ = await ML_Pipeline(build_patchtst_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1be82256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (16, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (14, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 13s - 118ms/step - auc: 0.4985 - loss: 0.7391 - val_auc: 0.5294 - val_loss: 0.6961\n",
      "Epoch 2/20\n",
      "108/108 - 13s - 116ms/step - auc: 0.5237 - loss: 0.7011 - val_auc: 0.5526 - val_loss: 0.6907\n",
      "Epoch 3/20\n",
      "108/108 - 13s - 116ms/step - auc: 0.5267 - loss: 0.6938 - val_auc: 0.5356 - val_loss: 0.6973\n",
      "Epoch 4/20\n",
      "108/108 - 13s - 116ms/step - auc: 0.5368 - loss: 0.6885 - val_auc: 0.5415 - val_loss: 0.6959\n",
      "Epoch 5/20\n",
      "108/108 - 13s - 117ms/step - auc: 0.5466 - loss: 0.6886 - val_auc: 0.5283 - val_loss: 0.6990\n",
      "Epoch 6/20\n",
      "108/108 - 13s - 116ms/step - auc: 0.5392 - loss: 0.6908 - val_auc: 0.5473 - val_loss: 0.6922\n",
      "Epoch 7/20\n",
      "108/108 - 12s - 115ms/step - auc: 0.5437 - loss: 0.6871 - val_auc: 0.5302 - val_loss: 0.6930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (32, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "MCFT: SideSignal.HOLD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/repositories/Live-Trading-Platform/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:947: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "symbol = \"MCFT\"\n",
    "side, _ = await ML_Pipeline(build_patchtst_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b33fc6",
   "metadata": {},
   "source": [
    "### GNN-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ec4a580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 9s - 83ms/step - auc: 0.4930 - loss: 0.7202 - val_auc: 0.5082 - val_loss: 0.7027\n",
      "Epoch 2/20\n",
      "108/108 - 9s - 83ms/step - auc: 0.4764 - loss: 0.7050 - val_auc: 0.5218 - val_loss: 0.6946\n",
      "Epoch 3/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.5197 - loss: 0.6920 - val_auc: 0.5502 - val_loss: 0.6926\n",
      "Epoch 4/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.5019 - loss: 0.6928 - val_auc: 0.5929 - val_loss: 0.6915\n",
      "Epoch 5/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.4754 - loss: 0.6937 - val_auc: 0.4650 - val_loss: 0.6949\n",
      "Epoch 6/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.5009 - loss: 0.6911 - val_auc: 0.4893 - val_loss: 0.6940\n",
      "Epoch 7/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.4846 - loss: 0.6936 - val_auc: 0.4810 - val_loss: 0.6928\n",
      "Epoch 8/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.5065 - loss: 0.6905 - val_auc: 0.5640 - val_loss: 0.6906\n",
      "Epoch 9/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.4917 - loss: 0.6924 - val_auc: 0.5549 - val_loss: 0.6905\n",
      "Epoch 10/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.4898 - loss: 0.6917 - val_auc: 0.5549 - val_loss: 0.6907\n",
      "Epoch 11/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.5073 - loss: 0.6903 - val_auc: 0.5233 - val_loss: 0.6908\n",
      "Epoch 12/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.4933 - loss: 0.6908 - val_auc: 0.5431 - val_loss: 0.6906\n",
      "Epoch 13/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.5025 - loss: 0.6900 - val_auc: 0.5035 - val_loss: 0.6919\n",
      "Epoch 14/20\n",
      "108/108 - 9s - 83ms/step - auc: 0.5061 - loss: 0.6900 - val_auc: 0.5281 - val_loss: 0.6912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "GOOG: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"GOOG\"\n",
    "side, _ = await ML_Pipeline(build_gnn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a43415fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 9s - 83ms/step - auc: 0.5248 - loss: 0.7076 - val_auc: 0.5535 - val_loss: 0.6909\n",
      "Epoch 2/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.5327 - loss: 0.6966 - val_auc: 0.4796 - val_loss: 0.7158\n",
      "Epoch 3/20\n",
      "108/108 - 9s - 83ms/step - auc: 0.5393 - loss: 0.6944 - val_auc: 0.5308 - val_loss: 0.6996\n",
      "Epoch 4/20\n",
      "108/108 - 9s - 84ms/step - auc: 0.5264 - loss: 0.6957 - val_auc: 0.5081 - val_loss: 0.6895\n",
      "Epoch 5/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.5239 - loss: 0.6917 - val_auc: 0.5571 - val_loss: 0.6864\n",
      "Epoch 6/20\n",
      "108/108 - 9s - 80ms/step - auc: 0.5302 - loss: 0.6914 - val_auc: 0.5433 - val_loss: 0.6868\n",
      "Epoch 7/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.5425 - loss: 0.6912 - val_auc: 0.5739 - val_loss: 0.6860\n",
      "Epoch 8/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.5355 - loss: 0.6899 - val_auc: 0.5666 - val_loss: 0.6861\n",
      "Epoch 9/20\n",
      "108/108 - 9s - 83ms/step - auc: 0.5462 - loss: 0.6873 - val_auc: 0.4575 - val_loss: 0.6962\n",
      "Epoch 10/20\n",
      "108/108 - 10s - 88ms/step - auc: 0.5421 - loss: 0.6895 - val_auc: 0.5515 - val_loss: 0.6893\n",
      "Epoch 11/20\n",
      "108/108 - 10s - 88ms/step - auc: 0.5490 - loss: 0.6886 - val_auc: 0.5390 - val_loss: 0.6886\n",
      "Epoch 12/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.5522 - loss: 0.6870 - val_auc: 0.5499 - val_loss: 0.6852\n",
      "Epoch 13/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.5539 - loss: 0.6882 - val_auc: 0.5281 - val_loss: 0.6901\n",
      "Epoch 14/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.5607 - loss: 0.6869 - val_auc: 0.5259 - val_loss: 0.6964\n",
      "Epoch 15/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.5405 - loss: 0.6885 - val_auc: 0.5423 - val_loss: 0.6855\n",
      "Epoch 16/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.5515 - loss: 0.6872 - val_auc: 0.5102 - val_loss: 0.6911\n",
      "Epoch 17/20\n",
      "108/108 - 9s - 81ms/step - auc: 0.5642 - loss: 0.6848 - val_auc: 0.5408 - val_loss: 0.6864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "AAPL: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"AAPL\"\n",
    "side, _ = await ML_Pipeline(build_gnn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "719ecf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 9s - 83ms/step - auc: 0.5275 - loss: 0.7178 - val_auc: 0.4747 - val_loss: 0.7033\n",
      "Epoch 2/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.5269 - loss: 0.7030 - val_auc: 0.5234 - val_loss: 0.7073\n",
      "Epoch 3/20\n",
      "108/108 - 10s - 88ms/step - auc: 0.5172 - loss: 0.6987 - val_auc: 0.5529 - val_loss: 0.6981\n",
      "Epoch 4/20\n",
      "108/108 - 9s - 86ms/step - auc: 0.5215 - loss: 0.6972 - val_auc: 0.5338 - val_loss: 0.6999\n",
      "Epoch 5/20\n",
      "108/108 - 9s - 83ms/step - auc: 0.5075 - loss: 0.6988 - val_auc: 0.4443 - val_loss: 0.7085\n",
      "Epoch 6/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.5232 - loss: 0.6942 - val_auc: 0.4248 - val_loss: 0.7093\n",
      "Epoch 7/20\n",
      "108/108 - 9s - 82ms/step - auc: 0.5088 - loss: 0.6984 - val_auc: 0.4440 - val_loss: 0.6995\n",
      "Epoch 8/20\n",
      "108/108 - 9s - 83ms/step - auc: 0.5150 - loss: 0.6954 - val_auc: 0.4936 - val_loss: 0.6988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "MCFT: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"MCFT\"\n",
    "side, _ = await ML_Pipeline(build_gnn_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb63759",
   "metadata": {},
   "source": [
    "### NAD-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac03d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 2s - 21ms/step - auc: 0.4739 - loss: 1.0084 - val_auc: 0.4802 - val_loss: 0.8265\n",
      "Epoch 2/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5078 - loss: 0.8390 - val_auc: 0.5343 - val_loss: 0.8234\n",
      "Epoch 3/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.4960 - loss: 0.7966 - val_auc: 0.5631 - val_loss: 0.7933\n",
      "Epoch 4/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5001 - loss: 0.7726 - val_auc: 0.5543 - val_loss: 0.7970\n",
      "Epoch 5/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5047 - loss: 0.7631 - val_auc: 0.5625 - val_loss: 0.7653\n",
      "Epoch 6/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5102 - loss: 0.7489 - val_auc: 0.5624 - val_loss: 0.7404\n",
      "Epoch 7/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5281 - loss: 0.7379 - val_auc: 0.5454 - val_loss: 0.7411\n",
      "Epoch 8/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5162 - loss: 0.7385 - val_auc: 0.5464 - val_loss: 0.7359\n",
      "Epoch 9/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5244 - loss: 0.7316 - val_auc: 0.5420 - val_loss: 0.7253\n",
      "Epoch 10/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.4937 - loss: 0.7311 - val_auc: 0.5559 - val_loss: 0.7224\n",
      "Epoch 11/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5300 - loss: 0.7266 - val_auc: 0.5467 - val_loss: 0.7355\n",
      "Epoch 12/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5194 - loss: 0.7264 - val_auc: 0.5411 - val_loss: 0.7321\n",
      "Epoch 13/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5180 - loss: 0.7225 - val_auc: 0.5489 - val_loss: 0.7242\n",
      "Epoch 14/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5319 - loss: 0.7191 - val_auc: 0.5434 - val_loss: 0.7284\n",
      "Epoch 15/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5167 - loss: 0.7196 - val_auc: 0.5489 - val_loss: 0.7165\n",
      "Epoch 16/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5240 - loss: 0.7160 - val_auc: 0.5443 - val_loss: 0.7154\n",
      "Epoch 17/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5332 - loss: 0.7156 - val_auc: 0.5548 - val_loss: 0.7214\n",
      "Epoch 18/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5243 - loss: 0.7165 - val_auc: 0.5506 - val_loss: 0.7220\n",
      "Epoch 19/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5313 - loss: 0.7152 - val_auc: 0.5479 - val_loss: 0.7144\n",
      "Epoch 20/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5367 - loss: 0.7155 - val_auc: 0.5452 - val_loss: 0.7177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "GOOG: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "symbol = \"GOOG\"\n",
    "side, _ = await ML_Pipeline(build_autoencoder_classifier_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed5d0ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 2s - 21ms/step - auc: 0.5106 - loss: 1.0813 - val_auc: 0.5247 - val_loss: 0.7557\n",
      "Epoch 2/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5306 - loss: 0.8842 - val_auc: 0.4793 - val_loss: 0.7521\n",
      "Epoch 3/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5227 - loss: 0.8367 - val_auc: 0.4888 - val_loss: 0.7458\n",
      "Epoch 4/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5023 - loss: 0.8165 - val_auc: 0.4999 - val_loss: 0.7354\n",
      "Epoch 5/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5076 - loss: 0.7909 - val_auc: 0.4778 - val_loss: 0.7253\n",
      "Epoch 6/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5461 - loss: 0.7752 - val_auc: 0.4989 - val_loss: 0.7206\n",
      "Epoch 7/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5197 - loss: 0.7736 - val_auc: 0.5355 - val_loss: 0.7196\n",
      "Epoch 8/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5033 - loss: 0.7654 - val_auc: 0.5177 - val_loss: 0.7159\n",
      "Epoch 9/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5361 - loss: 0.7557 - val_auc: 0.5347 - val_loss: 0.7129\n",
      "Epoch 10/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5205 - loss: 0.7500 - val_auc: 0.5392 - val_loss: 0.7114\n",
      "Epoch 11/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5163 - loss: 0.7522 - val_auc: 0.5178 - val_loss: 0.7095\n",
      "Epoch 12/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5340 - loss: 0.7459 - val_auc: 0.4733 - val_loss: 0.7157\n",
      "Epoch 13/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5210 - loss: 0.7488 - val_auc: 0.4548 - val_loss: 0.7138\n",
      "Epoch 14/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5537 - loss: 0.7372 - val_auc: 0.5098 - val_loss: 0.7114\n",
      "Epoch 15/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5436 - loss: 0.7386 - val_auc: 0.5074 - val_loss: 0.7088\n",
      "Epoch 16/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5259 - loss: 0.7392 - val_auc: 0.5273 - val_loss: 0.7048\n",
      "Epoch 17/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5115 - loss: 0.7421 - val_auc: 0.5103 - val_loss: 0.7046\n",
      "Epoch 18/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5251 - loss: 0.7376 - val_auc: 0.5384 - val_loss: 0.7045\n",
      "Epoch 19/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5579 - loss: 0.7307 - val_auc: 0.5382 - val_loss: 0.7036\n",
      "Epoch 20/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5308 - loss: 0.7328 - val_auc: 0.5239 - val_loss: 0.7004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "AAPL: SideSignal.HOLD\n"
     ]
    }
   ],
   "source": [
    "symbol = \"AAPL\"\n",
    "side, _ = await ML_Pipeline(build_autoencoder_classifier_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc5426ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 - 3s - 26ms/step - auc: 0.5035 - loss: 1.0267 - val_auc: 0.4614 - val_loss: 0.8840\n",
      "Epoch 2/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.4997 - loss: 0.8739 - val_auc: 0.4754 - val_loss: 0.8335\n",
      "Epoch 3/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5266 - loss: 0.8230 - val_auc: 0.4640 - val_loss: 0.8159\n",
      "Epoch 4/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5148 - loss: 0.8075 - val_auc: 0.4825 - val_loss: 0.8095\n",
      "Epoch 5/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5180 - loss: 0.7909 - val_auc: 0.4608 - val_loss: 0.7984\n",
      "Epoch 6/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5280 - loss: 0.7795 - val_auc: 0.4563 - val_loss: 0.7854\n",
      "Epoch 7/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5346 - loss: 0.7718 - val_auc: 0.4767 - val_loss: 0.7761\n",
      "Epoch 8/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5284 - loss: 0.7643 - val_auc: 0.4822 - val_loss: 0.7727\n",
      "Epoch 9/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5186 - loss: 0.7649 - val_auc: 0.4874 - val_loss: 0.7700\n",
      "Epoch 10/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5416 - loss: 0.7518 - val_auc: 0.4755 - val_loss: 0.7703\n",
      "Epoch 11/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5400 - loss: 0.7459 - val_auc: 0.4790 - val_loss: 0.7606\n",
      "Epoch 12/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5402 - loss: 0.7425 - val_auc: 0.4848 - val_loss: 0.7542\n",
      "Epoch 13/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5419 - loss: 0.7413 - val_auc: 0.4902 - val_loss: 0.7574\n",
      "Epoch 14/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5557 - loss: 0.7373 - val_auc: 0.4718 - val_loss: 0.7576\n",
      "Epoch 15/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5491 - loss: 0.7337 - val_auc: 0.4966 - val_loss: 0.7464\n",
      "Epoch 16/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5568 - loss: 0.7305 - val_auc: 0.4926 - val_loss: 0.7556\n",
      "Epoch 17/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5503 - loss: 0.7287 - val_auc: 0.4963 - val_loss: 0.7391\n",
      "Epoch 18/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5542 - loss: 0.7296 - val_auc: 0.4967 - val_loss: 0.7465\n",
      "Epoch 19/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5666 - loss: 0.7246 - val_auc: 0.4966 - val_loss: 0.7528\n",
      "Epoch 20/20\n",
      "108/108 - 0s - 2ms/step - auc: 0.5673 - loss: 0.7224 - val_auc: 0.5004 - val_loss: 0.7483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "MCFT: SideSignal.BUY\n"
     ]
    }
   ],
   "source": [
    "symbol = \"MCFT\"\n",
    "side, _ = await ML_Pipeline(build_autoencoder_classifier_lite, symbol, {})\n",
    "print(f\"{symbol}: {side}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
